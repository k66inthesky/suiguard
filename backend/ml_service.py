"""
ç¨ç«‹çš„ ML æ¨¡å‹æœå‹™
è² è²¬æ™ºèƒ½åˆç´„æ¼æ´æª¢æ¸¬ï¼Œä½¿ç”¨ LoRA å¾®èª¿çš„ Mistral-7B æ¨¡å‹
æ”¯æ´æ‡¶åŠ è¼‰å’Œå–®ä¾‹æ¨¡å¼ä»¥å„ªåŒ–è¨˜æ†¶é«”ä½¿ç”¨
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Dict, Optional
import os
import logging
from datetime import datetime
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel, LoraConfig, get_peft_model
import asyncio
from threading import Lock

# æ—¥èªŒé…ç½®
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ============================================
# æ™ºèƒ½è¨­å‚™é¸æ“‡ï¼ˆå„ªå…ˆ GPUï¼Œè‡ªå‹•é™ç´š CPUï¼‰
# ============================================
def get_device():
    """è‡ªå‹•åµæ¸¬ä¸¦é¸æ“‡æœ€ä½³è¨ˆç®—è¨­å‚™"""
    if torch.cuda.is_available():
        device = "cuda"
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        logger.info(f"ğŸ® åµæ¸¬åˆ° GPU: {gpu_name} ({gpu_memory:.1f} GB)")
        logger.info(f"âœ… ä½¿ç”¨ GPU åŠ é€Ÿ (CUDA {torch.version.cuda})")
        return device
    else:
        logger.warning("âš ï¸ æœªåµæ¸¬åˆ° GPUï¼Œé™ç´šä½¿ç”¨ CPU")
        logger.info("ğŸ’¡ å®‰è£ CUDA ç‰ˆæœ¬çš„ PyTorch ä»¥å•Ÿç”¨ GPU åŠ é€Ÿ")
        return "cpu"

# FastAPI æ‡‰ç”¨
app = FastAPI(
    title="SuiGuard ML Service",
    version="1.0.0",
    description="Dedicated ML service for smart contract vulnerability detection",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS è¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=False,
    allow_methods=["GET", "POST", "OPTIONS"],
    allow_headers=["*"],
)

# è«‹æ±‚æ¨¡å‹
class VulnerabilityAnalysisRequest(BaseModel):
    """æ¼æ´åˆ†æè«‹æ±‚"""
    move_code: str
    timeout: Optional[int] = 30  # ç§’
    
    class Config:
        min_anystr_length = 1

# ML æ¨¡å‹å–®ä¾‹ç®¡ç†å™¨
class MLModelSingleton:
    """ML æ¨¡å‹å–®ä¾‹ - æ‡¶åŠ è¼‰ï¼Œå…¨å±€å…±äº«"""
    
    _instance = None
    _lock = Lock()
    _model = None
    _tokenizer = None
    _initialized = False
    _loading = False
    _device = None  # è¨ˆç®—è¨­å‚™ï¼ˆcuda æˆ– cpuï¼‰
    
    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        """åˆå§‹åŒ–é…ç½®ï¼ˆä¸è¼‰å…¥æ¨¡å‹ï¼‰"""
        if not hasattr(self, '_config_loaded'):
            self.model_path = os.getenv("LORA_MODEL_PATH", "./lora_models")
            self.base_model_name = os.getenv("BASE_MODEL_NAME", "mistralai/Mistral-7B-Instruct-v0.2")
            
            # æ™ºèƒ½é¸æ“‡è¨­å‚™ï¼ˆå„ªå…ˆ GPUï¼‰
            if self._device is None:
                self._device = get_device()
            
            # æ¼æ´åˆ†é¡æ˜ å°„åˆ°é¢¨éšªåˆ†æ•¸å€é–“ (100åˆ†åˆ¶) - æ‰€æœ‰æ¼æ´éƒ½æ˜¯é«˜é¢¨éšª
            self.vulnerability_score_ranges = {
                "capability_leak": (80, 95),         # Capability Leak - é«˜é¢¨éšª
                "arithmetic_overflow": (80, 95),     # Arithmetic Overflow - é«˜é¢¨éšª
                "cross_module_pollution": (80, 95),  # Cross-Module Pollution - é«˜é¢¨éšª
                "unchecked_return": (80, 95),        # Unchecked Return - é«˜é¢¨éšª
                "resource_leak": (80, 95),           # Resource Leak - é«˜é¢¨éšª
                "safe": (0, 19)                      # Safe - ä½é¢¨éšª
            }
            
            # æ¼æ´é¡å‹çš„ä¸­æ–‡åç¨±
            self.vulnerability_names = {
                "capability_leak": "Capability Leak (æ¬Šé™æ´©æ¼)",
                "arithmetic_overflow": "Arithmetic Overflow (ç®—è¡“æº¢ä½)",
                "cross_module_pollution": "Cross-Module Pollution (è·¨æ¨¡çµ„æ±¡æŸ“)",
                "unchecked_return": "Unchecked Return (æœªæª¢æŸ¥è¿”å›å€¼)",
                "resource_leak": "Resource Leak (è³‡æºæ´©æ¼)",
                "safe": "æœªç™¼ç¾æ˜é¡¯æ¼æ´"
            }
            
            # æ©Ÿç‡åˆ†å¸ƒé–¾å€¼é…ç½®
            self.confidence_thresholds = {
                "high_confidence": 0.8,
                "medium_confidence": 0.6,
                "low_confidence": 0.4
            }
            
            self._config_loaded = True
            logger.info("âœ… ML æ¨¡å‹é…ç½®å·²è¼‰å…¥")
    
    async def ensure_model_loaded(self):
        """ç¢ºä¿æ¨¡å‹å·²è¼‰å…¥ï¼ˆæ‡¶åŠ è¼‰ï¼‰"""
        if self._initialized:
            return True
        
        # é˜²æ­¢é‡è¤‡è¼‰å…¥
        if self._loading:
            # ç­‰å¾…å…¶ä»–è«‹æ±‚å®Œæˆè¼‰å…¥
            while self._loading:
                await asyncio.sleep(0.5)
            return self._initialized
        
        with self._lock:
            if self._initialized:
                return True
            
            self._loading = True
            try:
                await self._load_model()
                self._initialized = True
                logger.info("âœ… ML æ¨¡å‹è¼‰å…¥å®Œæˆ")
                return True
            except Exception as e:
                logger.error(f"âŒ ML æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
                raise
            finally:
                self._loading = False
    
    async def _load_model(self):
        """å¯¦éš›è¼‰å…¥æ¨¡å‹ï¼ˆç§æœ‰æ–¹æ³•ï¼‰"""
        try:
            logger.info(f"ğŸ”„ é–‹å§‹è¼‰å…¥ LoRA æ¨¡å‹: {self.base_model_name}")
            
            # è¼‰å…¥ tokenizer
            logger.info("ğŸ“š è¼‰å…¥ tokenizer...")
            self._tokenizer = AutoTokenizer.from_pretrained(self.base_model_name)
            if self._tokenizer.pad_token is None:
                self._tokenizer.pad_token = self._tokenizer.eos_token
            
            # æ ¹æ“šè¨­å‚™é¡å‹é…ç½®æ¨¡å‹è¼‰å…¥åƒæ•¸
            if self._device == "cuda":
                # GPU æ¨¡å¼ï¼šä½¿ç”¨ float16 åŠ é€Ÿï¼Œæ”¯æ´è¨˜æ†¶é«”é™åˆ¶
                max_memory_gb = int(os.getenv("ML_MAX_MEMORY_GB", "10"))
                logger.info(f"ğŸ’¾ GPU è¨˜æ†¶é«”é™åˆ¶: {max_memory_gb}GB")
                
                logger.info("ğŸ§  è¼‰å…¥åŸºç¤æ¨¡å‹ (GPU æ¨¡å¼)...")
                base_model = AutoModelForCausalLM.from_pretrained(
                    self.base_model_name,
                    torch_dtype=torch.float16,  # GPU ä½¿ç”¨ FP16 åŠ é€Ÿ
                    device_map="cuda:0",
                    low_cpu_mem_usage=True
                )
            else:
                # CPU æ¨¡å¼ï¼šä½¿ç”¨ float32ï¼Œä¸éœ€è¦ device_map
                logger.info("ğŸ§  è¼‰å…¥åŸºç¤æ¨¡å‹ (CPU æ¨¡å¼)...")
                base_model = AutoModelForCausalLM.from_pretrained(
                    self.base_model_name,
                    torch_dtype=torch.float32,  # CPU ä½¿ç”¨ FP32
                    low_cpu_mem_usage=True
                )
                base_model = base_model.to(self._device)
            
            # è¼‰å…¥ LoRA å¾®èª¿æ¬Šé‡
            if os.path.exists(self.model_path):
                logger.info(f"ğŸ¯ è¼‰å…¥ LoRA å¾®èª¿æ¬Šé‡: {self.model_path}")
                try:
                    if self._device == "cuda":
                        # GPU æ¨¡å¼
                        self._model = PeftModel.from_pretrained(
                            base_model, 
                            self.model_path,
                            torch_dtype=torch.float16
                        )
                    else:
                        # CPU æ¨¡å¼
                        self._model = PeftModel.from_pretrained(
                            base_model, 
                            self.model_path,
                            torch_dtype=torch.float32
                        )
                    logger.info("âœ… LoRA æ¨¡å‹è¼‰å…¥æˆåŠŸ")
                except Exception as e:
                    logger.warning(f"âš ï¸ LoRA è¼‰å…¥å¤±æ•—ï¼Œç›´æ¥ä½¿ç”¨åŸºç¤æ¨¡å‹: {e}")
                    # å¦‚æœ LoRA è¼‰å…¥å¤±æ•—ï¼Œç›´æ¥ä½¿ç”¨åŸºç¤æ¨¡å‹
                    self._model = base_model
                    logger.info("âœ… ä½¿ç”¨åŸºç¤æ¨¡å‹ï¼ˆç„¡ LoRAï¼‰")
            else:
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ° LoRA æ¨¡å‹è·¯å¾‘: {self.model_path}")
                lora_config = LoraConfig(
                    r=8,
                    lora_alpha=16,
                    target_modules=["q_proj", "v_proj"],
                    lora_dropout=0.05,
                    bias="none",
                    task_type="CAUSAL_LM"
                )
                self._model = get_peft_model(base_model, lora_config)
            
            # è¨­ç½®ç‚ºè©•ä¼°æ¨¡å¼
            self._model.eval()
            
            # è¨˜æ†¶é«”ä½¿ç”¨å ±å‘Š
            if self._device == "cuda":
                memory_allocated = torch.cuda.memory_allocated() / 1024**3  # GB
                memory_reserved = torch.cuda.memory_reserved() / 1024**3  # GB
                logger.info(f"ğŸ“Š GPU è¨˜æ†¶é«”ä½¿ç”¨: {memory_allocated:.2f} GB (å·²åˆ†é…), {memory_reserved:.2f} GB (å·²ä¿ç•™)")
            else:
                logger.info("ğŸ“Š CPU æ¨¡å¼é‹è¡Œä¸­")
            
            logger.info(f"âœ… ML æ¨¡å‹è¼‰å…¥å®Œæˆ (è¨­å‚™: {self._device})")
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            raise
    
    def extract_label(self, output_text: str) -> str:
        """å¾è¼¸å‡ºæ–‡æœ¬æå–æ¼æ´æ¨™ç±¤ - å°æ‡‰5ç¨®é¡å‹"""
        output_lower = output_text.lower()
        
        # Resource Leak (è³‡æºæ´©æ¼)
        if "resource leak" in output_lower or "è³‡æºæ´©æ¼" in output_text or "èµ„æºæ³„æ¼" in output_text:
            return "resource_leak"
        # Arithmetic Overflow (ç®—è¡“æº¢ä½)
        elif "overflow" in output_lower or "æº¢ä½" in output_text or "æº¢å‡º" in output_text or "arithmetic" in output_lower:
            return "arithmetic_overflow"
        # Unchecked Return (æœªæª¢æŸ¥è¿”å›å€¼)
        elif "unchecked" in output_lower or "return" in output_lower or "æœªæª¢æŸ¥" in output_text or "è¿”å›å€¼" in output_text:
            return "unchecked_return"
        # Cross-Module Pollution (è·¨æ¨¡çµ„æ±¡æŸ“)
        elif "cross-module" in output_lower or "pollution" in output_lower or "è·¨æ¨¡çµ„" in output_text or "æ±¡æŸ“" in output_text:
            return "cross_module_pollution"
        # Capability Leak (æ¬Šé™æ´©æ¼)
        elif "capability" in output_lower or "access control" in output_lower or "æ¬Šé™" in output_text or "å­˜å–æ§åˆ¶" in output_text:
            return "capability_leak"
        # Safe (æœªç™¼ç¾æ˜é¡¯æ¼æ´)
        elif "æœªç™¼ç¾æ˜é¡¯æ¼æ´" in output_text or "æœªç™¼ç¾æ¼æ´" in output_text or "å®‰å…¨" in output_text or "safe" in output_lower:
            return "safe"
        else:
            # é»˜èªæ ¹æ“šå¸¸è¦‹é—œéµå­—åˆ¤æ–·
            if "é‚è¼¯" in output_text or "logic" in output_lower:
                return "arithmetic_overflow"
            elif "éš¨æ©Ÿ" in output_text or "random" in output_lower:
                return "unchecked_return"
            else:
                return "safe"
    
    async def classify_vulnerability(self, move_code: str) -> Dict:
        """ä½¿ç”¨ LoRA æ¨¡å‹åˆ†é¡æ™ºèƒ½åˆç´„æ¼æ´"""
        import time
        start_time = time.time()
        
        try:
            # ç¢ºä¿æ¨¡å‹å·²è¼‰å…¥
            await self.ensure_model_loaded()
            
            if not self._model or not self._tokenizer:
                raise Exception("æ¨¡å‹æœªæ­£ç¢ºåˆå§‹åŒ–")
            
            # æ§‹å»ºæç¤ºè©
            instruction = "è«‹åˆ†æä»¥ä¸‹ Sui Move æ™ºèƒ½åˆç´„ä»£ç¢¼ï¼Œæ‰¾å‡ºæ½›åœ¨çš„å®‰å…¨æ¼æ´ï¼Œä¸¦è©•ä¼°å±éšªç­‰ç´šï¼ˆé«˜/ä¸­/ä½ï¼‰"
            prompt = f"{instruction}\n\n```move\n{move_code}\n```\n\nåˆ†æçµæœï¼š"
            
            # åˆ†è©
            inputs = self._tokenizer(
                prompt,
                return_tensors="pt",
                max_length=2048,
                truncation=True,
                padding=True
            )
            
            # ç§»è‡³æ­£ç¢ºè¨­å‚™ï¼ˆGPU æˆ– CPUï¼‰
            inputs = {k: v.to(self._device) for k, v in inputs.items()}
            
            # ç”Ÿæˆé æ¸¬ - ä½¿ç”¨ç¢ºå®šæ€§æ¨ç†ï¼ˆgreedy decodingï¼‰
            with torch.no_grad():
                outputs = self._model.generate(
                    **inputs,
                    max_new_tokens=256,
                    do_sample=False,  # é—œé–‰éš¨æ©Ÿæ¡æ¨£ï¼Œä½¿ç”¨è²ªå©ªè§£ç¢¼
                    num_beams=1,      # ä¸ä½¿ç”¨ beam searchï¼Œä¿æŒä¸€è‡´æ€§
                    pad_token_id=self._tokenizer.pad_token_id,
                    eos_token_id=self._tokenizer.eos_token_id
                )
            
            # è§£ç¢¼è¼¸å‡º
            output_text = self._tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            # æå–åˆ†æçµæœéƒ¨åˆ†
            if "åˆ†æçµæœï¼š" in output_text:
                output_text = output_text.split("åˆ†æçµæœï¼š", 1)[1].strip()
            
            # æå–åˆ†é¡æ¨™ç±¤
            classification = self.extract_label(output_text)
            
            # è§£æå±éšªç­‰ç´šå’Œä¿¡å¿ƒåº¦
            confidence = 0.5  # é»˜èªä¿¡å¿ƒåº¦
            risk_level = "MEDIUM"
            
            if "å±éšªç­‰ç´šï¼šé«˜" in output_text or "é«˜é¢¨éšª" in output_text or "åš´é‡" in output_text:
                confidence = 0.9
                risk_level = "HIGH"
            elif "å±éšªç­‰ç´šï¼šä¸­" in output_text or "ä¸­é¢¨éšª" in output_text or "ä¸­ç­‰" in output_text:
                confidence = 0.6
                risk_level = "MEDIUM"
            elif "å±éšªç­‰ç´šï¼šä½" in output_text or "ä½é¢¨éšª" in output_text or "è¼•å¾®" in output_text:
                confidence = 0.3
                risk_level = "LOW"
            elif classification == "safe":
                confidence = 0.8
                risk_level = "SAFE"
            
            # æ§‹å»ºæ¦‚ç‡åˆ†å¸ƒ - æ›´æ–°ç‚º6ç¨®é¡å‹
            probabilities = {
                "capability_leak": 0.0,
                "arithmetic_overflow": 0.0,
                "cross_module_pollution": 0.0,
                "unchecked_return": 0.0,
                "resource_leak": 0.0,
                "safe": 0.0
            }
            
            # æ ¹æ“šåˆ†é¡è¨­ç½®æ¦‚ç‡
            probabilities[classification] = confidence
            remaining_prob = 1.0 - confidence
            other_count = len(probabilities) - 1
            for key in probabilities:
                if key != classification:
                    probabilities[key] = remaining_prob / other_count
            
            # è¨ˆç®—é¢¨éšªåˆ†æ•¸ (0-100)
            risk_score = self._calculate_risk_score(classification, confidence)
            
            # ç²å–æ¼æ´é¡å‹çš„ä¸­æ–‡åç¨±
            vulnerability_name = self.vulnerability_names.get(classification, classification)
            
            # è¨ˆç®—è™•ç†æ™‚é–“
            processing_time = time.time() - start_time
            
            return {
                "classification": classification,
                "vulnerability_type": vulnerability_name,  # æ·»åŠ ä¸­æ–‡åç¨±
                "probabilities": probabilities,
                "max_probability": confidence,
                "risk_score": risk_score,
                "risk_level": risk_level,
                "reasoning": output_text,
                "model_version": "LoRA-Mistral-7B-v1.0",
                "processing_time": round(processing_time, 2),
                "timestamp": datetime.now().isoformat() + "Z"
            }
            
        except Exception as e:
            logger.error(f"âŒ æ¼æ´åˆ†é¡å¤±æ•—: {e}")
            raise
    
    def _calculate_risk_score(self, classification: str, confidence: float) -> int:
        """è¨ˆç®— 0-100 é¢¨éšªåˆ†æ•¸"""
        score_range = self.vulnerability_score_ranges.get(classification, (0, 19))
        min_score, max_score = score_range
        
        # åŸºæ–¼ä¿¡å¿ƒåº¦åœ¨å€é–“å…§è¨ˆç®—åˆ†æ•¸
        base_score = min_score + (max_score - min_score) * confidence
        
        # ä¿¡å¿ƒåº¦èª¿æ•´
        if confidence >= self.confidence_thresholds["high_confidence"]:
            adjustment = 1.0
        elif confidence >= self.confidence_thresholds["medium_confidence"]:
            adjustment = 0.8
        elif confidence >= self.confidence_thresholds["low_confidence"]:
            adjustment = 0.6
        else:
            adjustment = 0.3
        
        final_score = base_score * adjustment
        return int(round(min(max(final_score, 0), 100)))
    
    def get_stats(self) -> Dict:
        """ç²å–æ¨¡å‹çµ±è¨ˆä¿¡æ¯"""
        stats = {
            "initialized": self._initialized,
            "loading": self._loading,
            "model_path": self.model_path,
            "base_model": self.base_model_name
        }
        
        if torch.cuda.is_available() and self._initialized:
            stats["gpu_memory_allocated_gb"] = torch.cuda.memory_allocated() / 1024**3
            stats["gpu_memory_reserved_gb"] = torch.cuda.memory_reserved() / 1024**3
        
        return stats

# å…¨å±€å–®ä¾‹å¯¦ä¾‹
ml_model = MLModelSingleton()

# API ç«¯é»
@app.get("/")
async def root():
    """æœå‹™åŸºæœ¬ä¿¡æ¯"""
    return {
        "service": "SuiGuard ML Service",
        "version": "1.0.0",
        "status": "ready",
        "model_initialized": ml_model._initialized,
        "endpoints": {
            "analyze": "/api/analyze-vulnerability",
            "health": "/health",
            "stats": "/stats"
        }
    }

@app.post("/api/analyze-vulnerability")
async def analyze_vulnerability(request: VulnerabilityAnalysisRequest):
    """åˆ†ææ™ºèƒ½åˆç´„æ¼æ´"""
    try:
        move_code = request.move_code.strip()
        
        if not move_code:
            raise HTTPException(status_code=400, detail="move_code is required")
        
        if len(move_code) > 100000:
            raise HTTPException(status_code=400, detail="Code too large (max: 100KB)")
        
        logger.info("ğŸ“ æ”¶åˆ°æ¼æ´åˆ†æè«‹æ±‚")
        
        # åŸ·è¡Œåˆ†æ
        result = await ml_model.classify_vulnerability(move_code)
        
        logger.info(f"âœ… åˆ†æå®Œæˆ: {result['classification']} (é¢¨éšªåˆ†æ•¸: {result['risk_score']})")
        
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ åˆ†æå¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"Analysis failed: {str(e)}")

@app.get("/health")
async def health_check():
    """å¥åº·æª¢æŸ¥"""
    return {
        "status": "healthy",
        "model_initialized": ml_model._initialized,
        "timestamp": datetime.now().isoformat() + "Z"
    }

@app.get("/stats")
async def get_stats():
    """ç²å–æœå‹™çµ±è¨ˆä¿¡æ¯"""
    return ml_model.get_stats()

@app.post("/api/warmup")
async def warmup():
    """é ç†±æ¨¡å‹ï¼ˆæ‰‹å‹•è§¸ç™¼è¼‰å…¥ï¼‰"""
    try:
        logger.info("ğŸ”¥ é–‹å§‹é ç†± ML æ¨¡å‹...")
        await ml_model.ensure_model_loaded()
        logger.info("âœ… æ¨¡å‹é ç†±å®Œæˆ")
        return {
            "status": "warmed_up",
            "stats": ml_model.get_stats()
        }
    except Exception as e:
        logger.error(f"âŒ é ç†±å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"Warmup failed: {str(e)}")

# å•Ÿå‹•é…ç½®
if __name__ == "__main__":
    import uvicorn
    
    port = int(os.getenv("ML_SERVICE_PORT", 8081))
    host = "0.0.0.0"
    
    logger.info(f"ğŸš€ Starting ML Service on http://{host}:{port}")
    
    uvicorn.run(
        app,
        host=host,
        port=port,
        log_level="info",
        access_log=False,
        reload=False,
        workers=1  # å–® workerï¼Œé¿å…é‡è¤‡è¼‰å…¥æ¨¡å‹
    )
